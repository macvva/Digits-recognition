{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__='Maciej Nowaczyk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we will take a look into the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ok so what are we going to do? Firstly, we will feed the neural network with the training data-> i.e.: \n",
    "train_images and train_labels. The network is supposed to learn to associate images and labels.\n",
    "Finally, we'll ask network to produce predictions for test_images, and we will verify whether these predictions match the labels from test_labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#weights = {\n",
    "#    'w1': tf.Variable(tf.compat.v1([n_input, n_hidden1], stddev=0.1)),\n",
    "#    'w2': tf.Variable(tf.compat.v1([n_hidden1, n_hidden2], stddev=0.1)),\n",
    "#    'w3': tf.Variable(tf.compat.v1([n_hidden2, n_hidden3], stddev=0.1)),\n",
    "#    'out': tf.Variable(tf.compat.v1([n_hidden3, n_output], stddev=0.1)),\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# reshape our training image data by flattening it\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "# scale our pixel values so that it fits between 0 and 1\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "# reshape our testing image data by flattening it\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "# scale our pixel values so that it fits between 0 and 1\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "\n",
    "\n",
    "# encode our train labels into a vector\n",
    "train_labels = to_categorical(train_labels)\n",
    "# endoe our test labels\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 1.4740 - accuracy: 0.6574\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.5848 - accuracy: 0.8544\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4095 - accuracy: 0.8897\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.3520 - accuracy: 0.9011\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.3229 - accuracy: 0.9080\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.3036 - accuracy: 0.9124\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2895 - accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=6, batch_size=128)\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9140999913215637\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[9]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\test\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\test\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(network, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ann_visualizer in c:\\users\\test\\anaconda3\\lib\\site-packages (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install ann_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\test\\anaconda3\\lib\\site-packages (0.14.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tpdf', '-O', 'network.gv'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2000cd726702>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mann_viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Neural Network for digit recognition\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ann_visualizer\\visualize.py\u001b[0m in \u001b[0;36mann_viz\u001b[1;34m(model, view, filename, title)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrowhead\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"none\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"#707070\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mview\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mview\u001b[1;34m(self, filename, directory, cleanup, quiet, quiet_view)\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mto\u001b[0m \u001b[0mretrieve\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mapplication\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mexit\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m--> 244\u001b[1;33m         return self.render(filename=filename, directory=directory,\n\u001b[0m\u001b[0;32m    245\u001b[0m                            \u001b[0mview\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                            quiet=quiet, quiet_view=quiet_view)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, quiet, quiet_view)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         rendered = backend.render(self._engine, format, filepath,\n\u001b[0m\u001b[0;32m    208\u001b[0m                                   \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                                   quiet=quiet)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mcwd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrendered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tpdf', '-O', 'network.gv'], make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "\n",
    "ann_viz(network, title=\"Neural Network for digit recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
